@INPROCEEDINGS {10204361,
author = { Liu, Yabo and Wang, Jinghua and Huang, Chao and Wang, Yaowei and Xu, Yong },
booktitle = { 2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) },
title = {{ CIGAR: Cross-Modality Graph Reasoning for Domain Adaptive Object Detection }},
year = {2023},
volume = {},
ISSN = {},
pages = {23776-23786},
abstract = { Unsupervised domain adaptive object detection (UDAOD) aims to learn a detector by generalizing knowledge from a labeled source domain to an unlabeled target domain. Though the existing graph-based methods for UDAOD perform well in some cases, they cannot learn a proper node set for the graph. In addition, these methods build the graph solely based on the visual features and do not consider the linguistic knowledge carried by the semantic prototypes, e.g., dataset labels. To overcome these problems, we propose a cross-modality graph reasoning adaptation (CIGAR) method to take advantage of both visual and linguistic knowledge. Specifically, our method performs cross-modality graph reasoning between the linguistic modality graph and visual modality graphs to enhance their representations. We also propose a discriminative feature selector to find the most discriminative features and take them as the nodes of the visual graph for both efficiency and effectiveness. In addition, we employ the linguistic graph matching loss to regulate the update of linguistic graphs and maintain their semantic representation during the training process. Comprehensive experiments validate the effectiveness of our proposed CIGAR. },
keywords = {Training;Visualization;Semantics;Prototypes;Object detection;Linguistics;Feature extraction},
doi = {10.1109/CVPR52729.2023.02277},
url = {https://doi.ieeecomputersociety.org/10.1109/CVPR52729.2023.02277},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =Jun}

